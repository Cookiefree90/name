Here's the first part of AVG_Developer_Guide.md, covering the Introduction and Implementation Overview:

# (AVG) - Developer Guide

Welcome to the Developer Guide for the (AVG) project, specifically tailored for the Financial Expert agent demonstration. This guide assumes the project structure and initial code have been generated by an LLM using the `avg/avg.json` master prompt.

## Table of Contents

1.  [Introduction](#introduction)
2.  [Implementation Overview](#implementation-overview)
    *   [Core AVG Toolkit (`adk_avg_toolkit`)](#core-avg-toolkit-adk_avg_toolkit)
    *   [Financial Expert Agent (`financial_expert_agent`)](#financial-expert-agent-financial_expert_agent)
3.  [Setup Instructions](#setup-instructions)
4.  [Running the Demo (Command-Line Interface)](#running-the-demo-command-line-interface)
5.  [Programmatic Usage (Python Orchestration)](#programmatic-usage-python-orchestration)
6.  [Configuration Deep Dive (`financial_knowledge_config.yaml`)](#configuration-deep-dive-financial_knowledge_configyaml)
7.  [Understanding `avg.json` (The Master Prompt)](#understanding-avgjson-the-master-prompt)

---

## 1. Introduction

 (AVG) is a modular toolkit designed to simplify the development and orchestration of sophisticated AI agents. It aims to provide a layer of abstraction over various Agent Development Kits (ADKs), promoting portability and reusability.

This guide focuses on the Financial Expert agent, an example implementation built using AVG and the Google Agent Development Kit (ADK). The Financial Expert is designed to:
*   Access and synthesize information from diverse financial data sources.
*   Utilize advanced techniques like Retrieval Augmented Generation (RAG).
*   Leverage configurable expertise pipelines for complex reasoning.
*   Integrate with Google ADK capabilities for functionalities like web search and API calls.

The entire project structure, including the core AVG toolkit and the financial expert agent code, is intended to be generated by a Large Language Model (LLM) based on the detailed specifications found in the `avg/avg.json` file within this project.

---

## 2. Implementation Overview

The project is primarily structured into two main Python packages: `adk_avg_toolkit` (the core AVG components) and `financial_expert_agent` (the specific application).

### Core AVG Toolkit (`adk_avg_toolkit`)

This package contains the foundational, reusable components of AVG:

*   **`knowledge_config_loader.py`**:
    *   **Purpose**: Loads and validates configurations for all knowledge-related aspects of an agent. This includes definitions for knowledge sources (APIs, databases, document collections), knowledge graphs, vector stores, data ingestion pipelines, and decision models.
    *   **Key Class**: `KnowledgeConfigLoader`
    *   **Functionality**: Parses YAML or JSON configuration files (like `financial_knowledge_config.yaml`), validates the structure, and provides getter methods for easy access to different configuration sections.

*   **`expertise_pipeline_manager.py`**:
    *   **Purpose**: Manages the definition, loading, and execution of "expertise pipelines." These pipelines represent sequences of operations or tasks that an agent performs, often involving multiple steps and leveraging various knowledge sources or expert modules.
    *   **Key Class**: `ExpertisePipelineManager`
    *   **Functionality**: Takes pipeline configurations (which can define steps, input/output mappings, and references to expert modules), instantiates necessary components (via an expert wrapper factory), and orchestrates the flow of data through the pipeline. Supports both predefined pipeline handlers and generic, step-based execution.

*   **`base_expert_wrapper.py`**:
    *   **Purpose**: Provides an Abstract Base Class (ABC) for creating standardized wrappers around underlying ADK agents or other specialized modules (e.g., a machine learning model, a specific data processing function).
    *   **Key Class**: `BaseExpertWrapper`
    *   **Functionality**: Defines a common interface (`initialize_adk_agent`, `process`, `get_capabilities`) that the `ExpertisePipelineManager` can use to interact with any "expert" module, regardless of its underlying implementation. Concrete subclasses will implement the specifics for interacting with, for example, a Google ADK `LlmAgent`.

### Financial Expert Agent (`financial_expert_agent`)

This package implements the specific Financial Expert agent using the AVG toolkit and Google ADK:

*   **`financial_expert_main_agent.py`**:
    *   **Purpose**: Contains the main logic for the Financial Expert agent (e.g., class `FinancialAdvisorMasterAgent`). This agent understands user queries, decomposes them into tasks, and uses the `ExpertisePipelineManager` to execute relevant financial analysis pipelines.
    *   **Functionality**: Initializes and uses `KnowledgeConfigLoader` (with `configs/financial_knowledge_config.yaml`) and `ExpertisePipelineManager`. It translates natural language financial queries into pipeline executions and coordinates the overall response generation. It's designed to be runnable within the Google ADK ecosystem.

*   **`expert_wrappers.py`**:
    *   **Purpose**: Contains concrete implementations of `BaseExpertWrapper` tailored for specific financial tasks.
    *   **Examples**:
        *   `CompanyDataRetriever`: Wraps an ADK `LlmAgent` to fetch company data.
        *   `MarketNewsAnalyzer`: Wraps an ADK `LlmAgent` for sentiment analysis or summarization of news.
        *   `ReportGenerator`: Wraps an ADK `LlmAgent` to generate formatted reports from processed data.
    *   **Functionality**: Each class implements `_initialize_adk_agent` to set up its specific ADK `LlmAgent` (model, instructions, capabilities derived from AVG configurations) and `process` to execute its specialized task.

*   **`tools.py`**:
    *   **Purpose**: Defines custom Google ADK capabilities specifically for the Financial Expert.
    *   **Examples**:
        *   `financial_web_search_tool`: For targeted web searches.
        *   `sec_edgar_api_tool`: For interacting with SEC EDGAR.
        *   `stock_price_api_tool`: For fetching stock prices.
    *   **Functionality**: These capabilities are designed to be used by the ADK `LlmAgent` instances within the financial expert wrappers.

*   **`configs/financial_knowledge_config.yaml`**:
    *   **Purpose**: The central configuration file defining all knowledge sources, ingestion pipelines, models, etc., specifically for the Financial Expert agent. This file is loaded by `KnowledgeConfigLoader`.

---
Let me know when you're ready for the next sections (Setup, CLI, Programmatic Usage).

Here are the next sections for AVG_Developer_Guide.md, covering Setup, CLI, and Programmatic Usage:

## 3. Setup Instructions

To get the AVG Financial Expert agent demo up and running, follow these steps. This assumes the project code has been generated by an LLM based on `avg/avg.json` into a repository (e.g., `avg_financial_expert_demo`).

1.  **Clone the Repository**:
    If the project is in a Git repository, clone it to your local machine:
    ```bash
    git clone <repository_url>
    cd avg_financial_expert_demo
    ```
    (Replace `<repository_url>` and `avg_financial_expert_demo` with the actual URL and directory name).

2.  **Python Version**:
    Ensure you have Python 3.9 or higher installed.

3.  **Create and Activate a Virtual Environment**:
    It's highly recommended to use a virtual environment to manage dependencies.
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate  # On Linux/macOS
    # For Windows: .venv\Scripts\activate.bat
    ```

4.  **Install Dependencies**:
    Install the required Python packages using the `requirements.txt` file.
    ```bash
    pip install -r requirements.txt
    ```

5.  **Set Up Environment Variables**:
    The application uses environment variables for configuration, especially for Google Cloud services and API keys.
    *   Copy the example environment file:
        ```bash
        cp .env.example .env
        ```
    *   Edit the `.env` file and provide your specific details:
        *   `GOOGLE_CLOUD_PROJECT`: Your Google Cloud Project ID.
        *   `GOOGLE_CLOUD_LOCATION`: The Google Cloud region for Vertex AI services (e.g., `us-central1`).
        *   `SEC_API_KEY` (Optional): If you plan to use a tool that directly queries the SEC EDGAR API and requires a key, uncomment and fill this in.
        *   Add any other API keys required by specific tools or knowledge sources you configure.

6.  **Authenticate with Google Cloud**:
    Ensure you have the Google Cloud CLI installed and authenticated for Application Default Credentials (ADC). The Google ADK will use these credentials when interacting with Vertex AI.
    ```bash
    gcloud auth application-default login
    ```
    Also, ensure the Vertex AI API is enabled in your Google Cloud project. Refer to the [Google ADK Quickstart](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-development-kit/quickstart) for more details if needed.

---

## 4. Running the Demo (Command-Line Interface)

The project includes a command-line script to demonstrate the Financial Expert agent's capabilities.

*   **Navigate to the project root directory.**
*   **Ensure your virtual environment is activated and `.env` file is correctly populated.**

To run the demo with predefined sample queries:
```bash
python demo/run_demo.py
The script will iterate through queries defined in demo/sample_queries.txt, pass them to the FinancialAdvisorMasterAgent, and print the agent's responses.

(The LLM generating demo/run_demo.py might include options for passing a single query directly via the command line. Refer to the generated script's help message if available, e.g., python demo/run_demo.py --help)

5. Programmatic Usage (Python Orchestration)
Beyond the demo script, you can programmatically interact with the AVG components and the Financial Expert agent. This is useful for embedding AVG into larger applications or for more complex interaction scenarios.

The following examples illustrate how you might initialize and use the core components. Assume these snippets are run from a Python script or Jupyter notebook within the project's root directory, with the virtual environment activated.

Example 1: Initializing Core AVG Components

import asyncio
import os
from dotenv import load_dotenv

from adk_avg_toolkit.knowledge_config_loader import KnowledgeConfigLoader
from adk_avg_toolkit.expertise_pipeline_manager import ExpertisePipelineManager
from financial_expert_agent.financial_expert_main_agent import FinancialAdvisorMasterAgent # Assuming this class name
from adk_avg_toolkit.base_expert_wrapper import BaseExpertWrapper # For type hinting

# Load environment variables (important for API keys and GCP settings)
load_dotenv()

# Define path to the main knowledge configuration file
# (Assumes the script is run from the project root)
KNOWLEDGE_CONFIG_PATH = "financial_expert_agent/configs/financial_knowledge_config.yaml"

def expert_wrapper_factory(expert_config: dict, knowledge_loader: KnowledgeConfigLoader) -> BaseExpertWrapper:
    """
    Factory function to create expert wrapper instances based on configuration.
    The LLM generating the project should implement a more robust version of this,
    potentially in financial_expert_main_agent.py or a dedicated factory module.
    This version needs to import the actual wrapper classes from financial_expert_agent.expert_wrappers
    """
    expert_type = expert_config.get("type")
    expert_id = expert_config.get("id", "unknown_expert")

    # Dynamically import from financial_expert_agent.expert_wrappers
    # This is a conceptual sketch; actual implementation depends on class names in expert_wrappers.py
    # from financial_expert_agent import expert_wrappers as financial_wrappers
    # concrete_wrapper_class = getattr(financial_wrappers, expert_type, None)
    # if concrete_wrapper_class and issubclass(concrete_wrapper_class, BaseExpertWrapper):
    #     return concrete_wrapper_class(avg_expert_config=expert_config, knowledge_loader=knowledge_loader)

    print(f"Warning: expert_wrapper_factory needs full implementation to map type '{expert_type}' to a concrete BaseExpertWrapper subclass from financial_expert_agent.expert_wrappers.")
    class DummyWrapper(BaseExpertWrapper):
        def _initialize_adk_agent(self, **kwargs):
            print(f"DummyWrapper: _initialize_adk_agent for {self.expert_id}")
            self._underlying_adk_agent = f"Dummy ADK Agent for {self.expert_id}"
        async def process(self, input_data: dict, **kwargs) -> any:
            print(f"DummyWrapper: process called for {self.expert_id} with {input_data}")
            return f"Dummy response from {self.expert_id} for query: {input_data.get('query')}"

    dummy_expert_config = {"id": expert_id, "type": expert_type, **expert_config}
    return DummyWrapper(avg_expert_config=dummy_expert_config)


async def main_programmatic_example():
    print("Initializing AVG components programmatically...")

    # 1. Initialize KnowledgeConfigLoader
    try:
        knowledge_loader = KnowledgeConfigLoader(config_path=KNOWLEDGE_CONFIG_PATH)
        print("KnowledgeConfigLoader initialized successfully.")
    except Exception as e:
        print(f"Error initializing KnowledgeConfigLoader: {e}")
        return

    # 2. Initialize ExpertisePipelineManager
    pipeline_definitions_from_config = knowledge_loader.config.get("expertise_pipelines", [])
    if not pipeline_definitions_from_config:
        print("Warning: No 'expertise_pipelines' found in knowledge configuration. ExpertisePipelineManager might be limited.")

    try:
        factory_with_knowledge = lambda conf: expert_wrapper_factory(conf, knowledge_loader)
        pipeline_manager = ExpertisePipelineManager(
            pipeline_configs=pipeline_definitions_from_config,
            knowledge_loader=knowledge_loader,
            expert_wrapper_factory=factory_with_knowledge
        )
        print("ExpertisePipelineManager initialized successfully.")
    except Exception as e:
        print(f"Error initializing ExpertisePipelineManager: {e}")
        return

    # 3. Initialize the FinancialAdvisorMasterAgent
    try:
        financial_agent = FinancialAdvisorMasterAgent(
            knowledge_config_path=KNOWLEDGE_CONFIG_PATH
            # The agent's __init__ might also take the pre-initialized loader and manager
        )
        print("FinancialAdvisorMasterAgent initialized successfully.")
    except Exception as e:
        print(f"Error initializing FinancialAdvisorMasterAgent: {e}")
        return

    # 4. Interact with the agent
    sample_query = "What's the market sentiment for MSFT based on recent news?"
    print(f"\nSending query to FinancialAdvisorMasterAgent: '{sample_query}'")

    try:
        # This conceptual call assumes FinancialAdvisorMasterAgent has a primary interaction method.
        # The actual method (e.g., handle_query, process_request, run_adk_agent_loop)
        # will be defined by the LLM based on the prompt in avg.json.
        if hasattr(financial_agent, "handle_user_request"):
            response = await financial_agent.handle_user_request(sample_query) # Or similar method
            print(f"Agent Response: {response}")
        else:
            print("FinancialAdvisorMasterAgent needs a primary method for handling user requests (e.g., handle_user_request). Check generated code.")

    except Exception as e:
        print(f"Error during agent interaction: {e}")

if __name__ == "__main__":
    asyncio.run(main_programmatic_example())

Note on expert_wrapper_factory: The robustness of this factory is key. The avg.json prompt should guide the LLM to implement a version that correctly imports and instantiates the concrete financial expert wrappers defined in financial_expert_agent/expert_wrappers.py based on the expert_config provided by the ExpertisePipelineManager.


Let me know when you're ready for the final sections: "Configuration Deep Dive" and "Understanding `avg.json`".
Here are the final sections for AVG_Developer_Guide.md, covering the Configuration Deep Dive and Understanding avg.json:

---

## 6. Configuration Deep Dive (`financial_knowledge_config.yaml`)

The file `financial_expert_agent/configs/financial_knowledge_config.yaml` is central to customizing the Financial Expert agent's knowledge and behavior without altering its core Python code. It's loaded by the `KnowledgeConfigLoader` from the `adk_avg_toolkit`.

Below is an explanation of its main sections and how to configure them. (The exact structure and available fields will correspond to what the LLM generates based on `avg/avg.json`'s `financial_knowledge_config_yaml` content prompt).

```yaml
# Example structure (refer to your actual generated file for exact fields)
# avg_financial_expert/configs/financial_knowledge_config.yaml

knowledge_sources:
  - name: "unique_source_name_1"  # Unique identifier for this source
    type: "api_endpoint"         # Type of source: api_endpoint, document_collection, database_table
    description: "Brief description of the source."
    uri: "https_://api.example.com/data" # Base URI for APIs, file path glob for documents, etc.
    access_params:                 # Parameters specific to accessing this source
      api_key_env_var: "MY_API_KEY"  # Name of environment variable holding an API key
      # Other params like rate_limit, specific query args, etc.
    data_schema_pointer: "optional/path/to/schema.json" # Optional: points to a data schema

  - name: "unstructured_reports_for_rag"
    type: "document_collection"
    path_glob: "/path/to/your/docs/**/*.pdf" # Glob pattern for local files
    ingestion_pipeline_ref: "name_of_ingestion_pipeline" # See 'ingestion_pipelines'

# ... more knowledge sources

knowledge_graphs:
  - name: "my_financial_kg"
    type: "graph_database_service_name" # e.g., Neo4j, JanusGraph (or generic 'graph_database')
    description: "Knowledge graph details."
    connection_alias: "main_graph_db_connection" # Alias for connection parameters
    query_language: "Cypher" # or SPARQL, GraphQL etc.

ingestion_pipelines:
  - name: "name_of_ingestion_pipeline"
    description: "Pipeline to process raw data into a usable knowledge format."
    steps:
      - processor: "type_of_processor_1" # e.g., pdf_text_extractor, text_chunker
        params: { param1: value1 }
      - processor: "embedding_generator"
        params: { model_id: "text-embedding-ada-002" } # Or other embedding model
      - processor: "vector_db_writer"
        params: { vector_db_ref: "name_of_vector_store" } # See 'vector_stores'

vector_stores:
  - name: "name_of_vector_store"
    type: "faiss_local" # Or pinecone, weaviate, etc.
    path: "/path/to/faiss_index_if_local" # Or connection details for remote stores
    # Other params like embedding_dimension, etc.

decision_models:
  - name: "my_decision_model"
    type: "decision_tree_classifier" # Or other model type (e.g., scikit-learn compatible)
    description: "Model for a specific decision-making task."
    model_path: "/path/to/serialized_model.pkl" # Path to .pkl, .onnx, etc.
    feature_set_pointer: "optional/path/to/feature_set_definition.json"

expertise_pipelines: # (This section might be part of financial_knowledge_config.yaml or separate)
  - name: "example_rag_pipeline"
    description: "A pipeline that performs RAG using specific knowledge sources and experts."
    steps:
      - name: "retrieve_context"
        expert_wrapper_id: "financial_news_retriever_expert" # ID of an expert defined elsewhere or implicitly
        expert_type: "FinancialNewsRetriever" # Maps to a concrete BaseExpertWrapper subclass
        input_mapping: {"query": "$current_data.user_query"} # How input flows to this step
        output_key: "retrieved_documents" # Key to store output in shared context

      - name: "generate_answer"
        expert_wrapper_id: "qa_generator_expert"
        expert_type: "QAGenerator"
        input_mapping: 
          query: "$current_data.user_query"
          context: "$shared_context.retrieved_documents"
        # output_key not specified, so its result becomes the pipeline's final output

# ... other sections like 'feature_sets', 'schemas', 'workflow_definitions'
Key Sections Explained:

knowledge_sources:

Define various places your agent can get information from.
type: Critical. Determines how the system tries to interact with it. Common types might be api_endpoint, document_collection, database_table.
uri: The access point (URL, file path pattern, database identifier).
access_params: Authentication (like API keys via environment variables), rate limits, etc.
ingestion_pipeline_ref: For sources like document collections that need processing (e.g., for RAG) before they can be used. Points to a definition in ingestion_pipelines.
knowledge_graphs:

Configuration for connecting to and querying graph databases.
ingestion_pipelines:

Define multi-step processes to transform raw data into usable knowledge (e.g., extracting text from PDFs, chunking, generating embeddings, and writing to a vector store).
Each step defines a processor (a function or module that does the work) and its params.
vector_stores:

Details about vector databases used for semantic search and RAG.
type: Specifies the kind of vector store (e.g., local FAISS, a cloud-based service).
decision_models:

Allows the agent to use pre-trained machine learning models for tasks like classification, prediction, or probabilistic reasoning.
model_path: Points to the serialized model file.
expertise_pipelines: (This might be part of the same file or loaded separately by ExpertisePipelineManager)

Defines named sequences of operations for complex tasks.
Each step typically involves an expert_wrapper_id (which should map to a configured BaseExpertWrapper instance) and expert_type (the class name of the wrapper).
input_mapping controls how data flows into a step (from initial query or previous steps' outputs stored in a shared_context).
output_key determines if a step's output is stored in shared_context for later steps or if it becomes the main data passed to the next step.
Customization: To adapt the Financial Expert agent, you would primarily:

Add or modify entries in knowledge_sources to point to your actual data.
Configure ingestion_pipelines if you have local documents for RAG.
Update vector_stores if you're using specific vector DB technologies.
Provide your own decision_models if applicable.
Define new expertise_pipelines or modify existing ones to change how the agent processes information and makes decisions.
Ensure any necessary API keys or credentials are in your .env file and referenced correctly in access_params (e.g., via api_key_env_var).
7. Understanding avg/avg.json (The Master Prompt)
The file avg/avg.json (which you, the developer, used to instruct an LLM to generate this entire project) is a crucial piece of meta-configuration. It acts as a detailed blueprint for the LLM.

Key Aspects of avg.json:

project_overview: Defines the high-level goals and target ADK.
target_repository_setup: Instructs the LLM on how to set up the repository (e.g., new repo vs. existing, name, license).
directory_structure: Specifies all the directories and files to be created, along with keys (content_generation_key) that map to detailed generation instructions.
content_generation_details: This is the core. For each content_generation_key:
It specifies the type of content (e.g., python_code, yaml_code, markdown_code).
It provides a description of the file's purpose.
Most importantly, it contains a content_prompt: a natural language instruction to the LLM on what specific content to generate for that file. These prompts encapsulate the detailed requirements for each script, class, method, and configuration that we discussed.
Why is this important for you as a developer of the generated code?

Understanding Origins: If you want to understand why a particular piece of code is structured the way it is, or why a certain file exists, avg.json often holds the original specification given to the LLM.
Guided Modifications: If you need to significantly modify or extend the project, looking at the corresponding content_prompt in avg.json can give you context on the original design intent.
Re-generation (Advanced): If you were to make changes to avg.json (e.g., add a new module or change a component's logic), you could potentially use it to re-prompt an LLM to regenerate parts of the project, though this requires careful handling to integrate with existing manual changes.
Example Snippet from avg.json's content_generation_details:

Looking at the entry for knowledge_config_loader_py in avg.json:

// "knowledge_config_loader_py": {
//   "type": "python_code",
//   "description": "Python class KnowledgeConfigLoader for loading and validating configurations...",
//   "content_prompt": "Generate the Python code for knowledge_config_loader.py as discussed. It should include the KnowledgeConfigLoader class with methods to load from YAML/JSON, validate (with extensible validation for sections like 'knowledge_sources', ...), and provide getter methods... Include the example if __name__ == '__main__': block..."
// },
This content_prompt is what guided the LLM to create the adk_avg_toolkit/knowledge_config_loader.py file with its specific class structure and methods.

By understanding avg.json, you gain insight into the "DNA" of the generated project.

This concludes the AVG Developer Guide. Remember that this project is a demonstration of the AVG toolkit concept applied to a financial use case, generated by an LLM. Further refinement, testing, and robust error handling would be needed for a production system.


This completes the content for `AVG_Developer_Guide.md`. I've finished that part of our work.
